<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Phongsakon Mark Konrad </title> <meta name="author" content="Phongsakon Mark Konrad"> <meta name="description" content="Personal website of Phongsakon Mark Konrad - Future Researcher with Entrepreneurial Spirit. Research Assistant at SDU, passionate about machine learning and deep learning. "> <meta name="keywords" content="machine-learning, deep-learning, research, entrepreneurship, software-engineering, AI"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;P&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://phomarkon.github.io/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <div class="alert alert-info" role="alert"> <strong>üöß Under Development</strong> - This website is currently under development and may contain template content. Please check back soon for updates! </div> <header class="post-header"> <h1 class="post-title"> Phongsakon Mark Konrad </h1> <p class="desc">Future Researcher with an Entrepreneurial Spirit</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/profile_img-480.webp 480w,/assets/img/profile_img-800.webp 800w,/assets/img/profile_img-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/profile_img.png?d6820499362549f5c014b6cc16d35ca2" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="profile_img.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p>üìß phongsakon@outlook.dk</p> <p>üìç S√∏nderborg, Region of Southern Denmark, Denmark</p> <p>üîó <a href="https://www.linkedin.com/in/phongsakonmarkkonrad" rel="external nofollow noopener" target="_blank">LinkedIn</a></p> </div> </div> <div class="clearfix"> <p><strong>TLDR:</strong> Nothing very special here, just a normal guy who likes deep learning.</p> <p><strong>Longer Version:</strong></p> <p>My path to research has been anything but direct. I moved from Thailand to Germany as a kid, spent four years in the <a href="https://www.bundeswehr.de/" rel="external nofollow noopener" target="_blank">Deutsche Marine (German Navy)</a>, and later co-founded two startups after coming to Denmark. What those experiences taught me is that my real drive isn‚Äôt building a business, but understanding how things learn and think. The questions that matter to me are academic ones.</p> <p>So now, I‚Äôm a software engineering undergraduate at the <a href="https://www.sdu.dk/en" rel="external nofollow noopener" target="_blank">University of Southern Denmark</a>, working as a research assistant in the <a href="https://www.sdu.dk/en/forskning/cis/laboratories/data-and-intelligence-lab" rel="external nofollow noopener" target="_blank">Data and Intelligence Lab</a> at the Centre for Industrial Software (CIS). My work is supervised by <a href="https://scholar.google.com/citations?user=ihaclQQAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Associate Professor Serkan Ayvaz</a>, who provides invaluable mentorship; he not only assigns me projects but also actively helps me to chase, discuss, and develop my own research ideas.</p> <p>I‚Äôm trying to absorb as much as I can across the field before a PhD. I‚Äôm interested in almost everything, but I can feel a definite pull. I‚Äôm drifting away from straightforward computer vision and more towards the cognitive and philosophical foundations of our work. My interest in psychology and neuroscience keeps leading me back to questions of thinking, reasoning, and what it even means for a model to be trustworthy.</p> <p>The idea that really grips me is the internal life of these models. The concept of ‚Äòmodel dreaming‚Äô - of a model learning from its own internally generated reality, feels important (interesting and fun). I suspect the next breakthroughs won‚Äôt just come from more data or bigger models, but from getting closer to these foundational principles of cognition. That‚Äôs the territory I want to spend my career exploring, starting with a PhD.</p> <p><strong>Languages:</strong></p> <ul> <li>German (Native)</li> <li>English (Professional Working)</li> <li>Thai (Native)</li> <li>Danish (Elementary)</li> </ul> <p><strong>(Top) Skills:</strong></p> <ul> <li>Machine Learning &amp; Deep Learning</li> <li>Research &amp; Academia</li> <li>Software Engineering</li> <li>Entrepreneurship</li> </ul> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">May 25, 2025</th> <td> My first paper has been accepted by KES 2025! See you in Osaka :) </td> </tr> <tr> <th scope="row" style="width: 20%">May 02, 2025</th> <td> Participating in MIT Global AI Hackathon 2025 </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 20, 2025</th> <td> Accepted for exchange at HKUST! Will be studying in Hong Kong from September to December 2025. </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 04, 2024</th> <td> Achieved Top Ten in DMAI 2024 (Danish AI Competition). </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 01, 2024</th> <td> Started my Research Assistant position at SDU under Assoiate Professor Serkan Ayvaz </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 15, 2023</th> <td> Completed 1st Place in SDU Case Competition </td> </tr> </table> </div> </div> <h2> <a href="/blog/" style="color: inherit">latest posts</a> </h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Jul 06, 2025</th> <td> <a class="news-title" href="/blog/2025/welcome/">Welcome</a> </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Accepted</abbr> <figure> <picture> <img src="/assets/img/publication_preview/complete_pipeline.drawio.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="complete_pipeline.drawio.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="konrad2025flood" class="col-sm-8"> <div class="title">Beyond Major Floods: Deep Learning for Detecting Shallow Water Inundation in Agricultural Areas</div> <div class="author"> Phongsakon Mark Konrad, Toygar Tanyel, and Serkan Ayvaz </div> <div class="periodical"> <em>29th International Conference on Knowledge-Based and Intelligent Information &amp; Engineering Systems (KES 2025), to be presented</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Flood detection using satellite imagery is crucial for environmental monitoring and disaster management, especially in rural and agricultural regions where even minor water inundation can disrupt farmland accessibility and road safety. Sentinel-1 Synthetic Aperture Radar (SAR) imagery offers a robust solution for mapping water under various weather conditions. Although deep learning-based segmentation methods have shown promising results for flood detection, their comparative performance in agricultural landscapes, including small-scale surface water dynamics, remains underexplored. In this study, we introduced a three-class segmentation framework that distinguishes sea, inland water, and land, improving the flood detection accuracy in complex coastal farmland. Ten different deep learning models were evaluated for segmentation using Sentinel-1 VH polarization decibel values. We further investigated anomaly detection via autoencoders and variational autoencoders to track temporal changes in flood-prone areas. To handle large-scale satellite imagery more effectively, we tiled the images, ensuring that the segmentation models could process high-resolution data efficiently. The evaluations showed that the DeepLabv3+ and hybrid ResNet-UNet models outperformed the others. Despite having a more lightweight architecture and lower computational and memory resource requirements, the ResNet-UNet model achieved predictive performance comparable to that of DeepLabv3+.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">WIP</abbr> <figure> <picture> <img src="/assets/img/publication_preview/brownian-motion.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="brownian-motion.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="konrad2025classical" class="col-sm-8"> <div class="title">Classical Comeback: Traditional Machine Learning Outperforms Deep Learning for Hyperspectral Fruit Quality Assessment</div> <div class="author"> Phongsakon Mark Konrad and Serkan Ayvaz </div> <div class="periodical"> <em>Work in Progress</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>The prevailing trend for complex tasks like hyperspectral data analysis is the immediate adoption of deep learning (DL) models. In this work, we challenge that default assumption in the context of fruit quality assessment. We investigate whether a meticulously engineered traditional machine learning (ML) pipeline can compete with or surpass more complex DL solutions on the DeepFruit-HS dataset. Our methodology emphasizes a rigorous application of classical principles. The pipeline incorporates strategic dataset rebalancing to mitigate class imbalances, comprehensive spectral feature engineering, and a two-phase ML approach. This involves extensive hyperparameter optimization via Optuna, followed by the construction of high-performing ensembles. Our findings demonstrate that this approach is highly effective. Optimized traditional models, particularly a Voting Ensemble and an Optuna-tuned Extra Trees classifier, achieve state-of-the-art F1 Macro scores of 0.7703 for ripeness and 0.8301 for firmness, respectively. These results outperform recent DL benchmarks on this dataset. This research highlights that a well-tuned classical ML pipeline represents a robust, interpretable, and powerful alternative for hyperspectral fruit quality assessment, meriting strong consideration before defaulting to more opaque DL architectures.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">WIP</abbr> <figure> <picture> <img src="/assets/img/publication_preview/wave-mechanics.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="wave-mechanics.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="konrad2025histology" class="col-sm-8"> <div class="title">How to Segment Images When You Have Almost No Data: An Empirical Comparison of Pre-training and Foundation Models</div> <div class="author"> Phongsakon Mark Konrad, Serkan Ayvaz, Yaser Sabzehmeidani, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Andrei-Alexandru Popa, Elisa Anamaria Liehn' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Work in Progress</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Deep learning models are notoriously data-hungry, which presents a fundamental obstacle for specialized medical tasks where annotated data is scarce. To overcome this, the dominant idea has been to fine-tune a network pre-trained on a large, related dataset. A more recent idea is to prompt a massive foundation model that has learned about the general structure of the visual world. It is not obvious which of these forms of knowledge transfer is more effective or efficient when the amount of target data is extremely small. To investigate this question, we perform a carefully controlled experiment on a clinically important problem: segmenting the layers of the artery wall from only nine annotated histology images. We compare a variety of standard convolutional architectures, pre-trained on a large public histology corpus, against a vision foundation model guided by a systematic and reproducible prompting curriculum. Our analysis goes beyond segmentation accuracy to include a practical assessment of computational trade-offs. This work aims to provide a clear benchmark and an intuitive understanding of which paradigm offers a more promising path forward for the many medical imaging tasks where data will always be a limiting factor.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Explorative</abbr> <figure> <picture> <img src="/assets/img/publication_preview/brownian-motion.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="brownian-motion.gif" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="konrad2025anomaly" class="col-sm-8"> <div class="title">Deep Patch Traversal: HS-SSAE‚Äôs Hierarchical SSM Layers for SAR Anomaly Detection</div> <div class="author"> Phongsakon Mark Konrad and Serkan Ayvaz </div> <div class="periodical"> <em>Explorative Research (Proof of concept completed, time-permitting)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Unsupervised anomaly detection in Synthetic Aperture Radar (SAR) time series is a critical task where conventional autoencoder-based methods often struggle, failing to adequately model the complex spatio-temporal dependencies in the data. This paper introduces a novel deep learning framework, the Hierarchical Spatial-Sequential Autoencoder with Dual Scoring (HS-SSAE-DS), designed for more robust detection in Sentinel-1 SAR imagery. The core insight of our HS-SSAE architecture is to model the intra-patch spatial dependencies hierarchically. It first employs General State Space Models (GeneralSSMs) to encode sequences of pixel rows. It then treats the resulting sequence of row-features as a new input to a second SSM, thereby capturing comprehensive spatial relationships within the patch. For anomaly identification, we propose a dual-scoring mechanism that synergistically combines the reconstruction error from the HS-SSAE with a temporal consistency score, which measures a patch‚Äôs deviation from its historical mean. This paper details the complete HS-SSAE-DS methodology and outlines its proposed evaluation for detecting diverse SAR anomalies. We argue that this architecture, with its integrated XAI component for enhanced interpretability, represents a significant step forward in the robust analysis of complex SAR time series.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%70%68%6F%6E%67%73%61%6B%6F%6E@%6F%75%74%6C%6F%6F%6B.%64%6B" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://www.linkedin.com/in/phongsakonmarkkonrad" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fa-solid fa-square-rss"></i></a> </div> <div class="contact-note">Feel free to reach out via email or connect with me on LinkedIn! </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2025 Phongsakon Mark Konrad. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: July 06, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>